# LLM API (use with LlamaIndex; set one you use)
OPENAI_API_KEY=
# Or for local / other providers, configure in pipeline/agent config
# ANTHROPIC_API_KEY=
# LLM_MODEL=openai:gpt-4o-mini

# Replicate API token (required for image indexing)
REPLICATE_API_TOKEN=

# Chroma: directory for persistent vector store (relative to project root or absolute)
CHROMA_PERSIST_DIR=data/wikiarch/index/chroma
CHROMA_COLLECTION_NAME=archlogic

# Text/logic indexing config
INDEX_EXTRACTION_DIR=data/wikiarch/extraction
INDEX_REFERENCE_DIR=data/wikiarch/index/reference
INDEX_WORKSPACE_DIR=data/wikiarch/index
INDEX_ENABLE_CLUSTER=1
INDEX_SHOW_PROGRESS=1
OPENAI_EMBEDDING_MODEL=text-embedding-3-large
OPENAI_EMBEDDING_DIM=1024

# Image indexing config
INDEX_RAW_DIR=data/wikiarch/raw
IMG_INDEX_OUTPUT_DIR=data/wikiarch/index/img_index
IMG_INDEX_MAX_WORKERS=4
IMG_INDEX_SHOW_PROGRESS=1
IMG_INDEX_VALIDATE_PATHS=1
IMG_INDEX_MAX_SIZE_KB=256

# Flask
FLASK_ENV=development
FLASK_DEBUG=1
